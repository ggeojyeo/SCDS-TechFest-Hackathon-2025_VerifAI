# verifiai (techfest-grp-53)

[Watch Our App Demo Here!](https://www.youtube.com/watch?v=t1TZVptV5cI&t=2s)

## **Contributers:**
| **Name**              | **Github Profile**                            | **Role**          |
|-----------------------|-----------------------------------------------|-------------------|
|   Adolphus            |[@ggeojyeo](https://github.com/ggeojyeo)       |   Backend         |
|   Afreen              |[@afreenrafi](https://github.com/afreenrafi)   |   Backend         |
|   Jia Wei             |[@maeganliew](https://github.com/maeganliew)   |   Frontend        |
|   Benjamin            |[@BenjaminKam](https://github.com/BenjaminKam) |   Frontend        |


## Inspiration
We’ve all seen wild claims online in which some make us laugh, others make us wonder, “Is this actually true?” In a world flooded with misinformation, we wanted to build a tool that helps cut through the noise and get to the truth. We wanted an all in one portal for both speech and image analysis.
What it does
We have 2 main features which are the Speech Fact-Checker – Speak a claim, and AI transcribes and verifies it. It also provides verified sources about the claim made. Secondly is our, Image Analysis – Upload, paste, or highlight text and our AI extracts the content, checks facts and detects bias. It can even detect if an article is satirical!

## How we built it
We built our web application using Next.js which is a React framework that helped us build the frontend and backend. For our backend, we mainly used Google Speech-To-Text API and OCR.
Challenges we ran into
The time crunch was real! One of the biggest challenges we faced was integrating our frontend and backend, especially since we chose to experiment with a new tech stack for this hackathon. While we were excited to push our limits, it also meant navigating unfamiliar territory, troubleshooting unexpected issues, and adapting on the fly. We ran into hurdles with API calls not returning expected data, ensuring real-time updates between components, and optimizing the AI response time to keep the user experience smooth. Debugging across different services while working against the clock was intense, but it also pushed us to think fast, collaborate efficiently, and problem-solve under pressure.

## Accomplishments that we're proud of
We are proud of creating an easy-to-use tool that checks facts in seconds, can seamlessly integrate voice, text, and image analysis and makes fact-checking more accessible to everyday users
Above all, we’re incredibly proud of ourselves for pulling through despite the challenges we faced. From tackling unfamiliar technologies to debugging under pressure, we pushed past obstacles, adapted quickly, and kept moving forward. Along the way, we learned new skills, strengthened our teamwork, and proved to ourselves that we could build something impactful in such a short time.

## What we learned
We learned how to build with Next.js, leveraging its server-side rendering and API routes for seamless frontend-backend integration. We also gained hands-on experience integrating multiple APIs and debugging API responses, optimizing data fetching, and handling asynchronous processing taught us valuable lessons in performance optimization and error handling. More importantly, we learned how to quickly adapt to new technologies under time constraints, strengthening our problem-solving and collaboration skills.

## What's next for verifAI
We are taking verifAI beyond text fact-checking with powerful new features. Our AI-Powered Deepfake Detector lets users upload images or videos for analysis to detect GAN fingerprints, lighting inconsistencies, and unnatural facial movements. Our Fact-Check Dashboard & Heatmap tracks user exposure to misinformation, visualizing interactions with trustworthy vs. biased sources. We will also provide monthly insights and influence scores on false claim exposure.
